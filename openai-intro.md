# Introduction to OpenAI

**OpenAI** is an artificial intelligence research laboratory and company known for developing  
advanced AI models, including the GPT (Generative Pre-trained Transformer) series. Their models  
power applications like natural language processing, code generation, and conversational agents.  
OpenAI provides APIs that allow developers to integrate AI capabilities into their own applications,  
making it easier to build intelligent, interactive, and automated systems. 

The **OpenAI library** is an official Python package developed by OpenAI to simplify working  
with their AI models. It lets you easily integrate powerful language models like GPT-4  
into your applications using straightforward Python code. You can send prompts, receive  
AI-generated responses, and manage API requests without complex setup.  
The library handles authentication, formatting, and parsing, so you can focus on building chatbots,  
content tools, or automation. Designed for simplicity, it makes advanced AI accessible  
even for developers new to machine learning.  


## Create a ChatGPT Platform Account

1. Open your browser and go to [https://platform.chatgpt.com](https://platform.chatgpt.com)  
   (you may be redirected to OpenAI’s developer platform).
3. Sign in with an existing account or create a new one using email, Google, or Microsoft.
4. Verify your email address if prompted.


## Add Billing and Credit

1. After logging in, open the **Billing** section from the dashboard.
2. Add a payment method (credit/debit card).
3. Purchase credits or enable pay-as-you-go billing.

> API usage requires an active billing setup.

## Create an API Key

1. In the dashboard, go to **API Keys**.
2. Click **Create new secret key**.
3. Copy the key and store it securely.

⚠️ Treat your API key like a password. Do not share it or commit it to source control.

## Install the OpenAI Client Library

Open Command Prompt or PowerShell:

```bash
pip install openai
```


## Configure Your API Key

Using *PowerShell*:

```powershell
setx OPENAI_API_KEY "your_api_key_here"
```

## Basic Python Example

This program demonstrates how to use the OpenAI Python SDK to interact with the **Responses API**,  
which is OpenAI’s unified interface for generating model outputs such as text. 

The **Responses API** is designed to replace older, separate APIs by supporting multiple output  
types (such as text or tool calls) within a single response object. In this example, only text  
output is requested, making it suitable for simple question-and-answer use cases. The API returns  
a rich response structure, but `output_text` simplifies access by concatenating all generated text  
segments into a single string.

```python
from openai import OpenAI

client = OpenAI()

response = client.responses.create(
    model="gpt-4.1-mini",
    input="Write a haiku about Python on Windows."
)

print(response.output_text)
```

This example demonstrates the simplest way to send a prompt to a ChatGPT model using the  
OpenAI Python SDK and retrieve the model’s text output. It uses the `responses.create()` method  
and the `output_text` convenience property, which automatically extracts and concatenates all text  
generated by the model into a single string. This approach is ideal for quick scripts, prototypes,  
and command-line tools where only the final text response is needed.  


## Setting API keys

If the API key is omitted, the OpenAI SDK automatically looks for it in the  
environment, typically using the `OPENAI_API_KEY` environment variable. This  
default behavior keeps sensitive credentials out of source code and enables  
safer key management across different machines, deployment targets, and  
version control systems. 

```python
from openai import OpenAI
import os

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

response = client.responses.create(
    model="gpt-4.1-mini",
    input="Write a haiku about Python on Windows."
)

print(response.output_text)
```


In this script, the API key is passed explicitly when creating the `OpenAI`  
client, which allows the SDK to authenticate requests to the OpenAI service.  
This approach makes the authentication mechanism visible in code and can be  
useful for quick tests or controlled environments, although it is generally  
not recommended for production due to security concerns.  

## Setting roles

```python
from openai import OpenAI

client = OpenAI()

response = client.responses.create(
    model="gpt-4.1-mini",
    input=[
        {
            "role": "system",
            "content": "You are an expert in Astronomy and Programming.",
        },
        {
            "role": "user",
            "content": "Is Pluto a planet?",
        },
    ],
)


# Convenience property: concatenated plain-text output
print("--- Text Output ---")
print(response.output_text)
```

The script initializes an `OpenAI` client and sends a structured conversational input  
to the `responses.create()` method. The input is provided as a list of message objects, allowing  
the model to process context in a dialogue-like format. Once the request is processed, the  
program retrieves and prints the model’s combined plain-text output using  
the convenience property `response.output_text`.

The **role setting** defines how each message should be interpreted by the model.    
The `system` role is used to establish high-level instructions or behavior, guiding   
the model to act as an expert in astronomy and programming. The `user` role represents  
the actual question being asked. By separating instructions (`system`) from queries (`user`),  
the model can more reliably follow constraints and produce relevant, context-aware answers.  



## Next Steps

* Review usage limits and pricing in the dashboard
* Explore different models for cost vs. quality
* Store secrets securely (e.g., Windows Credential Manager or .env files)

